{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Perceptrons</h3>\n",
    "<p></p>\n",
    "<li>is a single layer neural network</li>\n",
    "<li>is a linear classifier (binary)</li>\n",
    "<li>a multi-layer perceptron is called Neural Networks</li>\n",
    "<p>So how do perceptrons work?  A perceptron takes several binary inputs,\n",
    "<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-2-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><mo>&amp;#x2026;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-6\" style=\"width: 3.777em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.679em; height: 0px; font-size: 102%;\"><span style=\"position: absolute; clip: rect(1.914em, 1003.58em, 2.797em, -999.998em); top: -2.498em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-7\"><span class=\"msubsup\" id=\"MathJax-Span-8\"><span style=\"display: inline-block; position: relative; width: 0.885em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.434em, 1000.44em, 4.169em, -999.998em); top: -4.017em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-9\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.002em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.022em;\"></span></span><span style=\"position: absolute; top: -3.87em; left: 0.444em;\"><span class=\"mn\" id=\"MathJax-Span-10\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.022em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-11\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-12\" style=\"padding-left: 0.199em;\"><span style=\"display: inline-block; position: relative; width: 0.885em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.434em, 1000.44em, 4.169em, -999.998em); top: -4.017em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-13\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.002em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.022em;\"></span></span><span style=\"position: absolute; top: -3.87em; left: 0.444em;\"><span class=\"mn\" id=\"MathJax-Span-14\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.022em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-15\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mo\" id=\"MathJax-Span-16\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.199em;\">…</span></span><span style=\"display: inline-block; width: 0px; height: 2.502em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.198em; border-left: 0px solid; width: 0px; height: 0.703em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><mo>…</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-2\">x_1, x_2, \\ldots</script>, and produces a single binary output:\n",
    "</p>\n",
    "\n",
    "<img src=\"images/tikz0.png\">\n",
    "\n",
    "<p>what we mean binary output is an output with 0 as no and 1 as yes decision and the function that represents this scenario is called step function.This activation function is useful when the input pattern can only belong to one or two groups, that is, binary classification</p>\n",
    "In the example shown the perceptron has three inputs, $x_1, x_2, x_3$.\n",
    "In general it could have more or fewer inputs.  Rosenblatt proposed a\n",
    "simple rule to compute the output.  He introduced\n",
    "<em>weights</em>, $w_1,w_2,\\ldots$, real numbers\n",
    "expressing the importance of the respective inputs to the output.  The\n",
    "neuron's output, $0$ or $1$, is determined by whether the weighted sum\n",
    "$\\sum_j w_j x_j$ is less than or greater than some <em>threshold\n",
    "  value</em>.  Just like the weights, the\n",
    "threshold is a real number which is a parameter of the neuron.  To put\n",
    "it in more precise algebraic terms:\n",
    "<a class=\"displaced_anchor\" name=\"eqtn1\"></a>\\begin{eqnarray}\n",
    "  \\mbox{output} & = & \\left\\{ \\begin{array}{ll}\n",
    "      0 & \\mbox{if } \\sum_j w_j x_j \\leq \\mbox{ threshold} \\\\\n",
    "      1 & \\mbox{if } \\sum_j w_j x_j > \\mbox{ threshold}\n",
    "      \\end{array} \\right.\n",
    "\\tag{1}\\end{eqnarray}\n",
    "That's all there is to how a perceptron works!</p>\n",
    "\n",
    "\n",
    "<img alt=\"\" class=\"rr rs hp n o ho ab hm\" width=\"500\" height=\"300\" role=\"presentation\" src=\"images/1_n6sJ4yZQzwKL9wnF5wnVNg.png\">\n",
    "\n",
    "A way you can think about the\n",
    "perceptron is that it's a device that makes decisions by weighing up\n",
    "evidence.  Let me give an example.  It's not a very realistic example,\n",
    "but it's easy to understand, and we'll soon get to more realistic\n",
    "examples.  Suppose the weekend is coming up, and you've heard that\n",
    "there's going to be a cheese festival in your city.  You like cheese,\n",
    "and are trying to decide whether or not to go to the festival.  You\n",
    "might make your decision by weighing up three factors:\n",
    "<ol>\n",
    "<li> Is the weather good?\n",
    "<li> Does your boyfriend or girlfriend want to accompany you?\n",
    "<li> Is the festival near public transit? (You don't own a car).\n",
    "</ol>\n",
    "We can represent these three factors by corresponding binary variables\n",
    "$x_1, x_2$, and $x_3$.  For instance, we'd have $x_1 = 1$ if the\n",
    "weather is good, and $x_1 = 0$ if the weather is bad.  Similarly, $x_2\n",
    "= 1$ if your boyfriend or girlfriend wants to go, and $x_2 = 0$ if\n",
    "not.  And similarly again for $x_3$ and public transit.</p><p>Now, suppose you absolutely adore cheese, so much so that you're happy\n",
    "to go to the festival even if your boyfriend or girlfriend is\n",
    "uninterested and the festival is hard to get to.  But perhaps you\n",
    "really loathe bad weather, and there's no way you'd go to the festival\n",
    "if the weather is bad.  You can use perceptrons to model this kind of\n",
    "decision-making.  One way to do this is to choose a weight $w_1 = 6$\n",
    "for the weather, and $w_2 = 2$ and $w_3 = 2$ for the other conditions.\n",
    "The larger value of $w_1$ indicates that the weather matters a lot to\n",
    "you, much more than whether your boyfriend or girlfriend joins you, or\n",
    "the nearness of public transit.  Finally, suppose you choose a\n",
    "threshold of $5$ for the perceptron.  With these choices, the\n",
    "perceptron implements the desired decision-making model, outputting\n",
    "$1$ whenever the weather is good, and $0$ whenever the weather is bad.\n",
    "It makes no difference to the output whether your boyfriend or\n",
    "girlfriend wants to go, or whether public transit is nearby.</p><p>By varying the weights and the threshold, we can get different models\n",
    "of decision-making.  For example, suppose we instead chose a threshold\n",
    "of $3$.  Then the perceptron would decide that you should go to the\n",
    "festival whenever the weather was good <em>or</em> when both the\n",
    "festival was near public transit <em>and</em> your boyfriend or\n",
    "girlfriend was willing to join you.  In other words, it'd be a\n",
    "different model of decision-making.  Dropping the threshold means\n",
    "you're more willing to go to the festival.</p><p>Obviously, the perceptron isn't a complete model of human\n",
    "decision-making!  But what the example illustrates is how a perceptron\n",
    "can weigh up different kinds of evidence in order to make decisions.\n",
    "And it should seem plausible that a complex network of perceptrons\n",
    "could make quite subtle decisions:\n",
    "\n",
    "<img src=\"images/tikz1.png\"/>\n",
    "\n",
    "to put it in more descriptive way:\n",
    "    this is how it works\n",
    "    \n",
    "<li>All the inputs x are multiplied with their weights w. Let’s call it k\n",
    "    \n",
    "<img src=\"images/1__Zy1C83cnmYUdETCeQrOgA.png\" width=\"500\" height=\"300\" style=\"padding-top:50px;padding-bottom:50px;\"/>\n",
    "</li>\n",
    "<li>  Add all the multiplied values and call them Weighted Sum\n",
    "\n",
    "<img src=\"images/1_xFd9VQnUM1H0kiCENsoYxg.gif\" width=\"500\" height=\"300\" style=\"padding-top:50px;padding-bottom:50px;\"/></li>\n",
    "\n",
    "<li> Apply that weighted sum to the correct Activation Function.\n",
    "<img src=\"images/1_0iOzeMS3s-3LTU9hYH9ryg.png\"  width=\"500\" height=\"300\" style=\"padding-top:50px;padding-bottom:50px;\"/>\n",
    "</li>\n",
    "    \n",
    "<h3>Weights</h3> \n",
    "Weights shows the strength of the particular node.\n",
    "\n",
    "<h3>Bias</h3>\n",
    "A bias value allows you to shift the activation function curve up or down.\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
